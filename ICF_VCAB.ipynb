{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data from the vtc-cab repos\n",
    "raw_data = pd.read_csv('./activities_201802011009.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name accountid  userid                                    id deviceid  \\\n",
      "0  watch   7041046     NaN  99ef7d20-f289-11e7-824b-fda2ff9f7794  Android   \n",
      "1  watch   7041046     NaN  16836d10-f28a-11e7-a231-9114f613577e  Android   \n",
      "2  watch   7041046     NaN  b280e9d0-f4cf-11e7-b167-f75a20dec89d  Android   \n",
      "3  watch   7041046     NaN  6dd1cb50-f4d0-11e7-a231-9114f613577e  Android   \n",
      "4  watch   7041046     NaN  199f1e11-f4d1-11e7-824b-fda2ff9f7794  Android   \n",
      "\n",
      "                                    key  \\\n",
      "0                          LYS005228795   \n",
      "1         tapchiclbvidaibayernmunich_1p   \n",
      "2  tapchiderbyrealmadridvsbarcelona_lep   \n",
      "3              aquayoga4tuthechienbinhp   \n",
      "4                          LYS013573731   \n",
      "\n",
      "                                            metadata               tstamp  \\\n",
      "0  [Synopsis=Từ 04/04/2017, Title=ON FOOTBALL, bo...  2018-01-06 09:30:46   \n",
      "1  [Synopsis=, Title=Tạp chí CLB vĩ đại - Bayern ...  2018-01-06 09:34:15   \n",
      "2  [Synopsis=, Title=Tạp chí Derby - Real Madrid ...  2018-01-09 06:57:34   \n",
      "3  [Synopsis=Khoe va Dep, Title=Aqua Yoga 4 Tư th...  2018-01-09 07:02:49   \n",
      "4  [Synopsis=Nhịp đập 360° thể thao, Title=Nhịp đ...  2018-01-09 07:07:37   \n",
      "\n",
      "      value  \n",
      "0  watching  \n",
      "1  watching  \n",
      "2  watching  \n",
      "3  watching  \n",
      "4  watching  \n",
      "(173364, 9)\n"
     ]
    }
   ],
   "source": [
    "# Preview the ratings dataframe\n",
    "print(raw_data.head())\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['accountid'].replace('', np.nan, inplace=True)\n",
    "raw_data['key'].replace('', np.nan, inplace=True)\n",
    "raw_data.dropna(subset=['accountid'], inplace=True)\n",
    "raw_data.dropna(subset=['key'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers: 32729\n",
      "Number of items bought: 13575\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many items and customers there are in the dataset\n",
    "num_cust = len(raw_data.accountid.unique())\n",
    "num_items = len(raw_data.key.unique())\n",
    "print('Number of customers: ' + str(num_cust))\n",
    "print('Number of items bought: ' + str(num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add one quantity column to dataframe, for simple we just add 1 to everywhere\n",
    "raw_data['quantity'] = 1\n",
    "# add more quantity for the completed video to denote the stonger preference \n",
    "raw_data[raw_data['value'] == 'complete']['quantity'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean up the raw data \n",
    "retail_data = raw_data.loc[pd.isnull(raw_data.accountid) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173364, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retail_data = retail_data[:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's group purchase quantities by Stock Code and CustomerID\n",
    "retail_data = retail_data[['key', 'quantity', 'accountid']]\n",
    "retail_grouped = retail_data.groupby(['accountid', 'key']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountid</th>\n",
       "      <th>key</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>LYS005056949</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>LYS014206049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>annaandthekingm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>astrademovideo4km</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>changtraicuaem_tap2_4km</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>changtraicuaem_tap3_4km</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>garfieldm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>killerconstablem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>marvelstheavengersm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5129035-TV1</td>\n",
       "      <td>mousehuntm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accountid                      key  quantity\n",
       "0  5129035-TV1             LYS005056949         2\n",
       "1  5129035-TV1             LYS014206049         1\n",
       "2  5129035-TV1          annaandthekingm         1\n",
       "3  5129035-TV1        astrademovideo4km         1\n",
       "4  5129035-TV1  changtraicuaem_tap2_4km         2\n",
       "5  5129035-TV1  changtraicuaem_tap3_4km         3\n",
       "6  5129035-TV1                garfieldm         1\n",
       "7  5129035-TV1         killerconstablem         1\n",
       "8  5129035-TV1      marvelstheavengersm         1\n",
       "9  5129035-TV1               mousehuntm         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Matrix of grouped purchases\n",
      "     accountid                      key  quantity\n",
      "0  5129035-TV1             LYS005056949         2\n",
      "1  5129035-TV1             LYS014206049         1\n",
      "2  5129035-TV1          annaandthekingm         1\n",
      "3  5129035-TV1        astrademovideo4km         1\n",
      "4  5129035-TV1  changtraicuaem_tap2_4km         2\n"
     ]
    }
   ],
   "source": [
    "# If the quantity sum is 0, replace with 1 to indicate that there was a purchase of that item atleast\n",
    "retail_grouped.quantity.loc[retail_grouped.quantity == 0] = 1\n",
    "\n",
    "# Filter out all negative quantities so that we can focus the recommendation of items that the customer purchased and liked\n",
    "retail_grouped_final = retail_grouped[retail_grouped.quantity > 0]\n",
    "print ('\\nFinal Matrix of grouped purchases')\n",
    "print (retail_grouped_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get list of unique customers\n",
    "cust_list = list(np.sort(retail_grouped_final.accountid.unique()))\n",
    "# Get list of unique items bought\n",
    "item_list = list(np.sort(retail_grouped_final.key.unique()))\n",
    "# Get list of all the purchase quantities\n",
    "quantity_list = list(retail_grouped_final.quantity)\n",
    "\n",
    "\n",
    "# Building the matrix....\n",
    "mat_rows = retail_grouped_final.accountid.astype('category', categories = cust_list).cat.codes\n",
    "mat_cols = retail_grouped_final.key.astype('category', categories = item_list).cat.codes\n",
    "\n",
    "purchases_mat = sparse.csr_matrix((quantity_list, (mat_rows, mat_cols)), shape = (len(cust_list), len(item_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sparse matrix (13423, 8422)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<13423x8422 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 47165 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Shape of sparse matrix \" + str(purchases_mat.shape))\n",
    "purchases_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity Percentage in Ratings Matrix is 99.96\n"
     ]
    }
   ],
   "source": [
    "# Let's check how sparse the matrix is \n",
    "# Get all possible combination of purchases\n",
    "purchase_mat_size = purchases_mat.shape[0]*purchases_mat.shape[1]\n",
    "# Get actual number of item purchased\n",
    "num_purchases = len(purchases_mat.nonzero()[0])\n",
    "sparse_per = 100*(1 - (num_purchases/purchase_mat_size))\n",
    "print ('Sparsity Percentage in Ratings Matrix is ' + str(round(sparse_per,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSplit into test and train by masking some values of the dataset in the training set with 0s indicating the customer did not purchase.\\nThen run the model on the complete matrix and see if the predicted values are equal to the original values before masking\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Split into test and train by masking some values of the dataset in the training set with 0s indicating the customer did not purchase.\n",
    "Then run the model on the complete matrix and see if the predicted values are equal to the original values before masking\n",
    "\n",
    "'''\n",
    "\n",
    "def create_train(matrix_data, mask_pct = 0.2):\n",
    "    '''\n",
    "    This function will take in the complete customer-item matrix and \"mask\" a percentage of the original purchases where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original purchases, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original purchases matrix. \n",
    "    \n",
    "    args:\n",
    "    matrix_data - the original purchases matrix from which you want to generate a train/test set. Takes sparse csr_matrix form.\n",
    "    \n",
    "    mask_pct - The percentage of customer-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the customer-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original purchase matrix converted to binary - 1 indicates purchase and 0 indicates no purchase.\n",
    "    \n",
    "    user_inds - From the randomly selected customer-item indices, which customer rows were altered in the training data.\n",
    "    '''\n",
    "    # Prepare the test set\n",
    "    test_mat = matrix_data.copy()\n",
    "    test_mat[test_mat != 0] = 1\n",
    "    # Prepare the training set\n",
    "    training_mat = matrix_data.copy()\n",
    "    # Get indices of purchases in the matrix\n",
    "    purchase_idx = training_mat.nonzero()\n",
    "    # Get corresponding user-item indices of the purchase\n",
    "    purchase_pairs = list(zip(purchase_idx[0], purchase_idx[1]))\n",
    "    random.seed(0)\n",
    "    # Number of samples to mask\n",
    "    num_samples = int(np.ceil(mask_pct*len(purchase_pairs)))\n",
    "    # Randomly sample from the purchases\n",
    "    samples = random.sample(purchase_pairs, num_samples)\n",
    "    customer_idx = [index[0] for index in samples]\n",
    "    item_idx = [index[1] for index in samples]\n",
    "    # Mask the items in the above indentified indices as 0\n",
    "    training_mat[customer_idx, item_idx] = 0 \n",
    "    # To save space, eliminate the zeros in the sparse matrix\n",
    "    training_mat.eliminate_zeros()\n",
    "    return training_mat, test_mat, list(set(customer_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13423x8422 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 37732 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<13423x8422 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 47165 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the create_train function\n",
    "train_mat, test_mat, customer_idx = create_train(purchases_mat)\n",
    "train_mat\n",
    "test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### ALS Matrix Factorization\n",
    "### Reference : http://yifanhu.net/PUB/cf.pdf\n",
    "\n",
    "\n",
    "def implicit_weighted_ALS(training_mat, lambda_val = 0.1, alpha = 40, iterations = 10, rank_size = 20, seed = 0):\n",
    "    '''\n",
    "    args:\n",
    "    training_mat - Matrix with shape m x n; m = number of customers, n = number of items\n",
    "    \n",
    "    lambda_val - Regularization constraint for bias-variance trade-off. Increasing lambda_val increases bias but reduced variance\n",
    "    \n",
    "    alpha - Parameter describing the confidence of the matrix. The paper identified 40 as most effective. Descreasing this value will decrease the confidence between various purchases.\n",
    "    \n",
    "    iterations - Number of times to alternate between the customer feature vector (U) and item feature vector (V) in ALS. More iterations will give better convergence but increase computation.\n",
    "    \n",
    "    rank_size - Number of latent features in the customer/item feature vectors. Paper recommends between 20-200. Increasing may overfit but reduce bias.\n",
    "    \n",
    "    seed - internal state of random number generator.\n",
    "    \n",
    "    returns:\n",
    "    U (feature vector for customers) and V (feature vector for item.)\n",
    "    U.dot(V) would give us the predicted purchases matrix.\n",
    "    '''\n",
    "    \n",
    "    # Create confidence Matrix of size m x n\n",
    "    conf = (alpha*training_mat)\n",
    "    num_cust = conf.shape[0]\n",
    "    num_item = conf.shape[1]\n",
    "    \n",
    "    # Initial U/V feature vectors randomly\n",
    "    state = np.random.RandomState(seed)\n",
    "    # Create the customer feature vector with random numbers of size m x rank_size (number of latent features)\n",
    "    U = sparse.csr_matrix(state.normal(size = (num_cust, rank_size)))\n",
    "    # Create the item feature vector with random numbers of size n x rank_size (number of latent features). Will transpose it later\n",
    "    V = sparse.csr_matrix(state.normal(size = (num_item, rank_size)))\n",
    "    \n",
    "    # Create a sparse matrix with 1s along the diagonal for U\n",
    "    U_diag = sparse.eye(num_cust)\n",
    "    # Create a sparse matrix with 1s along the diagonal for V\n",
    "    V_diag = sparse.eye(num_item)\n",
    "    # Create a sparse matrix of 1s along the diagonal of the latent feature vector and the regularitzation term\n",
    "    lambda_diag = lambda_val * sparse.eye(rank_size)\n",
    "    \n",
    "    # Set up iterations\n",
    "    # Iterate between solving for U with V fixed and vice versa\n",
    "    for step in range(iterations):\n",
    "        print(\"step: {}\".format(step+1))\n",
    "        # Compute vTv and uTu before to save computing time\n",
    "        vTv = V.T.dot(V)\n",
    "        uTu = U.T.dot(U)\n",
    "        # Begin iteration to solve for U on fixed V\n",
    "        for u in range(num_cust):\n",
    "            # Convert customer row from confidence matrix to dense vector\n",
    "            conf_samp = conf[u,:].toarray()\n",
    "            pref = conf_samp.copy()\n",
    "            # Create a binary preference vector\n",
    "            pref[pref != 0] = 1\n",
    "            # Beging solving through the equations defined in the paper\n",
    "            # Cu -I term\n",
    "            CuI = sparse.diags(conf_samp, [0])\n",
    "            # yT(Cu-I)Y term\n",
    "            vTCuIV = V.T.dot(CuI).dot(V)\n",
    "            # yTCuPu term where we add the diagonal back in\n",
    "            vTCupu = V.T.dot(CuI + V_diag).dot(pref.T)\n",
    "            # Solve for Xu = ((yTy + yT(Cu-I)Y + lambda*I)^-1)yTCuPu\n",
    "            U[u] = spsolve(vTv + vTCuIV + lambda_diag, vTCupu)\n",
    "            \n",
    "        # Begin iteration to solve for V on fixed U\n",
    "        for v in range(num_item):\n",
    "            # Transpose item row from confidence matrix to dense vector\n",
    "            conf_samp = conf[:,v].T.toarray()\n",
    "            pref = conf_samp.copy()\n",
    "            # Create a binary preference vector\n",
    "            pref[pref != 0] = 1\n",
    "            # Beging solving through the equations defined in the paper\n",
    "            # Cu -I term\n",
    "            CvI = sparse.diags(conf_samp, [0])\n",
    "            # xT(Cv-I)X term\n",
    "            uTCvIU = U.T.dot(CvI).dot(U)\n",
    "            # xTCuPu term where we add the diagonal back in\n",
    "            uTCvpv = U.T.dot(CvI + U_diag).dot(pref.T)\n",
    "            # Solve for Yv = ((xTx + xT(Cu-I)X) + lambda*I)^-1)xTCvPv\n",
    "            V[v] = spsolve(uTu + uTCvIU + lambda_diag, uTCvpv)\n",
    "            \n",
    "    return U, V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1\n",
      "step: 2\n",
      "step: 3\n",
      "step: 4\n",
      "step: 5\n",
      "step: 6\n",
      "step: 7\n",
      "step: 8\n",
      "step: 9\n",
      "step: 10\n",
      "step: 11\n",
      "step: 12\n",
      "step: 13\n",
      "step: 14\n",
      "step: 15\n",
      "step: 16\n",
      "step: 17\n",
      "step: 18\n",
      "step: 19\n",
      "step: 20\n",
      "step: 21\n",
      "step: 22\n",
      "step: 23\n",
      "step: 24\n",
      "step: 25\n",
      "step: 26\n",
      "step: 27\n",
      "step: 28\n",
      "step: 29\n",
      "step: 30\n"
     ]
    }
   ],
   "source": [
    "# Call the function with lambda_val 0.1, alpha 40, 30 iterations and 10 latent features\n",
    "cust_vecs, item_vecs = implicit_weighted_ALS(train_mat, lambda_val=0.1, alpha = 40, iterations = 30, rank_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the first customer across the first 5 items\n",
    "cust_vecs[0:,].dot(item_vecs).toarray()[0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_mat, altered_custs, predictions, test_mat):\n",
    "    '''\n",
    "    args:\n",
    "    training_mat - The orginial training_mat where we masked some customers' purchases to zero. \n",
    "    \n",
    "    altered_custs - The indices of the customers where atleast one customer/item pair was altered to 0.\n",
    "    \n",
    "    predictions - The matrix of predicted purchases. These should be stored in a list, with customer vectors as item zero and item vectors as item one.\n",
    "    \n",
    "    test_mat - The test matrix constructed from the create_train function\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC of the test set only on customer-item iteractions that were originally zero to test ranking ability in addition to most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    store_auc = []\n",
    "    popularity_auc = []\n",
    "    # Get sum of item interactions to get most popular items\n",
    "    popular_items = np.array(test_mat.sum(axis =0)).reshape(-1)\n",
    "    item_vecs = predictions[1]\n",
    "    for cust in altered_custs:\n",
    "        # Get the training matrix row where the interactions were zero\n",
    "        training_row = training_mat[cust, :].toarray().reshape(-1)\n",
    "        zero_inds = np.where(training_row == 0)\n",
    "        # Get the predicted values based on our customer/item vectors\n",
    "        cust_vec = predictions[0][cust,:]\n",
    "        pred = cust_vec.dot(item_vecs).toarray()[0, zero_inds].reshape(-1)\n",
    "        # Get only items that were originally zero\n",
    "        actual = test_mat[cust,:].toarray()[0, zero_inds].reshape(-1)\n",
    "        popular = popular_items[zero_inds]\n",
    "        # Calculate AUC for predicted vs actual\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(actual, pred)\n",
    "        store_auc.append(metrics.auc(fpr, tpr))\n",
    "        # Calculate AUC for popular vs actual\n",
    "        fpr_pop, tpr_pop, thresholds_pop = metrics.roc_curve(actual, popular)\n",
    "        popularity_auc.append(metrics.auc(fpr_pop, tpr_pop))\n",
    "        \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mean_auc(train_mat, customer_idx, [sparse.csr_matrix(cust_vecs), sparse.csr_matrix(item_vecs)], test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sampling the Recommendations provide using the item:desc dictionary we had created earlier\n",
    "\n",
    "customers_arr = np.array(cust_list)\n",
    "items_arr = np.array(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_items_purchased(customer_id, train_mat, customers_arr, items_arr):\n",
    "    '''\n",
    "    Returns the items purchased by a specific customer in the training set\n",
    "    \n",
    "    args:\n",
    "    customer_id - ID of a customer whose made atleast one purchase\n",
    "    train_mat - The initial purchase matrix that we masked a percentage of\n",
    "    customers_arr - Array of customers in the purchase matrix\n",
    "    items_arr - Array of items in the purchase matrix\n",
    "    item_lookup - Dictionary of unique item ID to description\n",
    "    \n",
    "    returns:\n",
    "    A dictionary of stock_cd and description of those items already purchased\n",
    "    '''\n",
    "    # Get the index of the row where that customer ID is present\n",
    "    cust_ind = np.where(customers_arr == customer_id)[0][0]\n",
    "    # Get all the indices of the purchases made\n",
    "    purchase_ind = train_mat[cust_ind,:].nonzero()[1]\n",
    "    # Retrieve the product codes for the purchase indices\n",
    "    stock = items_arr[purchase_ind]\n",
    "    # Look up the description for the stock code from itemDescDict\n",
    "    #subdict = {x: item_lookup[x] for x in stock_codes if x in item_lookup}\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at what the first 5 customers purchased\n",
    "for cust in customers_arr[:9]:\n",
    "    print('Customer ID: ', cust)\n",
    "    print(get_items_purchased(cust, train_mat, customers_arr, items_arr))\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's write a function to get the recommended items for each of these customers using our recommendation engine\n",
    "\n",
    "def get_rec_item(customer_id, train_mat, customer_vecs, items_vecs, customer_arr, item_arr, num_items = 10):\n",
    "    '''\n",
    "    This function will return the top num_items recommended items to the customers\n",
    "    \n",
    "    args:\n",
    "    customer_id - ID of a customer who we want to see the recommendations for\n",
    "    train_mat - The initial purchase matrix that we masked a percentage of\n",
    "    customers_arr - Array of customers in the purchase matrix\n",
    "    items_arr - Array of items in the purchase matrix\n",
    "    item_lookup - Dictionary of unique item ID to description\n",
    "    num_items - The number of recommended items in order of best recommendation to lowest.\n",
    "    \n",
    "    returns:\n",
    "    The top n recommendations based on the U/V vectors for items never purchased/interacted with before\n",
    "    '''\n",
    "    # Get index of customerID\n",
    "    cust_ind = np.where(customer_arr == customer_id)[0][0]\n",
    "    # Get purchases made by that customer\n",
    "    pref_vec = train_mat[cust_ind,:].toarray()\n",
    "    # Add 1 to all purchases so that items not purchased yet become equal to 1\n",
    "    pref_vec = pref_vec.reshape(-1) + 1\n",
    "    # Make items that were already purchased 0 (so that they don't get included in the recommendation)\n",
    "    pref_vec[pref_vec > 1] = 0\n",
    "    # Get dot product of customer vector across all items in the item vector\n",
    "    rec_vector = customer_vecs[cust_ind,:].dot(item_vecs).toarray()\n",
    "    # Scale the recommendations between 0 and 1 using MinMax\n",
    "    scaler = MinMaxScaler()\n",
    "    rec_vector_scaled = scaler.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "    # Multiply by the purchased vector so that items already purchased are set to 0\n",
    "    recommend_vector = pref_vec*rec_vector_scaled\n",
    "    # Sort the indices in order of recommendations\n",
    "    item_idx = np.argsort(recommend_vector)[::-1][:num_items]\n",
    "    # Get the list of recommended items\n",
    "    rec_list = []\n",
    "    for index in item_idx:\n",
    "        stock_code = item_arr[index]\n",
    "        rec_list.append(stock_code)\n",
    "    return rec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at what was recommended for the 3 customers\n",
    "for cust in customers_arr[:9]:\n",
    "    print('Customer ID: ', cust)\n",
    "    print(get_rec_item(cust, train_mat, cust_vecs, item_vecs, customers_arr, items_arr))\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Let's compare the items bought vs the items recommended by customer in a dataframe so \n",
    "that we can see more clearly how the recommendation engine did\n",
    "'''\n",
    "\n",
    "def compare_purchase_rec(accountid, key, rec_list):\n",
    "    '''\n",
    "    This function returns a dataframe with the 10 purchased items and top 10 recommended items for each customer\n",
    "    \n",
    "    args:\n",
    "    customer_id - The customer ID in the purchase matrix\n",
    "    purchase_dict - The output of the get_items_purchased function which is a dictionary of stock_cd:description of items purchased\n",
    "    rec_list - The output of the get_rec_item function which is a list of the top n stock_cd and description pairs\n",
    "    \n",
    "    returns:\n",
    "    A dataframe with all purchased items and top n recommended items by customer\n",
    "    '''\n",
    "    # Create dataframes of one column each - CustomerID, Purchased items, Recommended Items\n",
    "    cust_df = pd.DataFrame({'CustID': [accountid]})\n",
    "    purchase_df = pd.DataFrame({'PurchasedItem': list(key)})\n",
    "    rec_df = pd.DataFrame({'RecommendedItem': [pair for pair in rec_list]})\n",
    "\n",
    "    # Column wise concatenate the dataframes\n",
    "    final_df = pd.concat([cust_df, purchase_df, rec_df], ignore_index=True, axis=1)\n",
    "    # Format the final dataframe\n",
    "    final_df.columns = ['CustID', 'PurchasedItem', 'RecommendedItem']\n",
    "    final_df['PurchasedItem'] = final_df.PurchasedItem.astype(str)\n",
    "    final_df['RecommendedItem'] = final_df.RecommendedItem.astype(str)\n",
    "    final_df = final_df.fillna('')\n",
    "    final_df = final_df.replace('nan', '', regex=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the same 3 customers\n",
    "for cust in customers_arr[10:12]:\n",
    "    print(tabulate(compare_purchase_rec(cust, \n",
    "                               get_items_purchased(cust, train_mat, customers_arr, items_arr),\n",
    "                               get_rec_item(cust, train_mat, cust_vecs, item_vecs, customers_arr, items_arr)),\n",
    "                  headers= ['CustID', 'PurchasedItem', 'RecommendedItem']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
